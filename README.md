# Image Captioning with BLIP

This project demonstrates how to generate descriptive captions for images using the **BLIP (Bootstrapped Language-Image Pretraining)** model from Hugging Face Transformers.

---

## **Requirements**

Make sure you have Python installed. Then install the required packages:

```bash
pip install transformers torch pillow
